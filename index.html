<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="speech.css">
    <title>Document</title>
</head>
<body>
    <section>
        <h1>Speech<br> Recognition</h1>
        <p>Available In Chrome😎 Only</p>
        <div class="container">
          <div class="texts">
          </div>
        </div>
    </section>
</body>
<script>
const texts = document.querySelector(".texts");
let p = document.createElement("p");
const replay = "replay";
const boss = "boss";

// time to waiting for speaking
var time = 0;

// speech to text
var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
const recognition = new SpeechRecognition();

// text to speak
var synth = window.speechSynthesis;

// save voices from synth
let voices =[];

// config speech
recognition.interimResults = true;
recognition.lang = 'vi-VI' || 'en-US';
recognition.continuous = false

// speaking function
let speak = (text) => {
  let utter = new SpeechSynthesisUtterance(text);
  utter.voice = voices[49];
  utter.rate = 0.75;
  synth.speak(utter);
  utter.onerror = (err) => {
    console.error(err)
  }
}

//print text to web
let showText = function (classes, text) {
  p= document.createElement("p");
  p.classList.add(classes);
  p.innerText = text;
  texts.appendChild(p);
}

let welcome = () => {
  let firstContent = "Good morning sir.";
  let secondContent = "How can I help you?";
  setTimeout(() => {
    showText(replay,firstContent);
    speak(firstContent);
  }, 300);
  setTimeout(() => {
    showText(replay,secondContent);
    speak(secondContent);
    
  }, 1800);
  setTimeout(() => {
    showText(boss,"...");
    recognition.start();
  }, 3200);
}

// receive sound from user and processing
recognition.addEventListener("result", (e) => {
  texts.appendChild(p);
  const text = Array.from(e.results)
    .map((result) => result[0])
    .map((result) => result.transcript)
    .join("");

  p.innerText = text;  
  if (e.results[0].isFinal) {
    if (text.includes("Xin chào")) {
      let contentSpeak = " how can I help you?";
      showText(replay, contentSpeak);
      speak(contentSpeak);
      time =1000 + replay.length * 55;
    }
    if (text.toLowerCase().includes("hello")) {
      let contentSpeak = "hello sir.";
      showText(replay, contentSpeak);
      speak(contentSpeak);
      time =1000 + contentSpeak.length * 55;
    }
    if (
      text.toLowerCase().includes("how are you") ||
      text.includes("khỏe không")) {
      let contentSpeak = "I'm fine thanks, and you?";
      showText(replay, contentSpeak);
      speak(contentSpeak);
      time = 1000 + contentSpeak.length * 55
    }
    if (
      text.toLowerCase().includes("what's your name") ||
      text.toLowerCase().includes("what is your name")
    ) {
      let contentSpeak = "My name is Laughing";
      showText(replay, contentSpeak);
      speak(contentSpeak);
      time = 1000 + contentSpeak.length * 55
    }
    if (text.includes("open my YouTube")) {
      p = document.createElement("p");
      p.classList.add("replay");
      p.innerText = "opening youtube channel";
      texts.appendChild(p);
      console.log("opening youtube");
      speak("opening youtube");
      window.open("https://www.youtube.com/channel/UCdxaLo9ALJgXgOUDURRPGiQ");
    }
    p = document.createElement("p");
  }
});


recognition.addEventListener("end", () => {
  setTimeout(() => {
    recognition.start();
    console.log('started');
    time = 0;
  }, time);
});

//get voices
if (synth.onvoiceschanged !== undefined) {synth.onvoiceschanged = () => {
  voices = synth.getVoices();
  }
}
setTimeout(() => {
  welcome();
}, 500);

</script>
</html>